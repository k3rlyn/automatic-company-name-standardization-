# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18qkd4iVfsTccAwdPbSy4kKvhuXdPAGGF
"""

# Install dependencies
from rapidfuzz import fuzz, process
import pandas as pd
import gdown
import re
# from google.colab import files
# from google.colab import drive
# drive.mount('/content/drive')

import streamlit as st
import pandas as pd
import numpy as np
import re
import time
import random
from io import BytesIO
import google.generativeai as genai
from rapidfuzz import fuzz, process
from tqdm import tqdm
import zipfile
import os

# Konfigurasi halaman
st.set_page_config(
    page_title="Company Name Standardization Tool",
    page_icon="üè¢",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Fungsi untuk setup Gemini API
def setup_gemini_api(api_key):
    """Setup Gemini API dengan key yang diberikan"""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash-lite-preview-06-17')
        return model
    except Exception as e:
        st.error(f"Error setting up Gemini API: {str(e)}")
        return None

# Fungsi pembersihan nama
def bersihkan_nama(nama):
    """Membersihkan nama perusahaan untuk fuzzy matching"""
    if pd.isna(nama):
        return ''
    nama = str(nama).lower()
    nama = re.sub(r'\b(pt|tbk|ltd|co|inc)\b', '', nama)
    nama = re.sub(r'[^\w\s]', '', nama)
    nama = re.sub(r'\s+', ' ', nama)
    return nama.strip()

def ambil_alias(nama):
    """Mengambil alias dari nama dalam tanda kurung"""
    if not isinstance(nama, str):
        return None
    match = re.search(r'\((.*?)\)', nama)
    if match:
        return match.group(1).lower().strip()
    return None

def is_singapore_address(alamat):
    """Cek apakah alamat di Singapura"""
    if pd.isna(alamat):
        return False
    alamat_lower = str(alamat).lower()
    singapore_keywords = ['singapore', 'singapura', 'science park', 'sg']
    return any(keyword in alamat_lower for keyword in singapore_keywords)

# Fungsi untuk membuat dictionary referensi
def create_reference_dict(reference_dfs):
    """Membuat dictionary referensi dari dataframes referensi"""
    standard_dict = {}

    for df in reference_dfs:
        if 'company_name_standardized' in df.columns:
            for idx, row in df.iterrows():
                standar = row['company_name_standardized']
                if pd.notna(standar):
                    # Dari kolom company_name jika ada
                    if 'company_name' in df.columns and pd.notna(row.get('company_name')):
                        nama_bersih = bersihkan_nama(row['company_name'])
                        if nama_bersih:
                            standard_dict[nama_bersih] = standar
                            alias = ambil_alias(row['company_name'])
                            if alias:
                                standard_dict[alias] = standar

                    # Dari kolom company_name_standardized
                    nama_bersih = bersihkan_nama(standar)
                    if nama_bersih:
                        standard_dict[nama_bersih] = standar
                        alias = ambil_alias(standar)
                        if alias:
                            standard_dict[alias] = standar

    return standard_dict

# Fungsi fuzzy matching
def match_nama_with_location(nama_input, alamat, standard_dict, threshold=90):
    """Fuzzy matching dengan pengecekan lokasi"""
    if pd.isna(nama_input) or nama_input == '-':
        return None

    nama_input_lower = str(nama_input).lower()
    choices = list(standard_dict.keys())

    # Pengecekan khusus untuk Shopee
    if 'shopee' in nama_input_lower:
        if is_singapore_address(alamat):
            return 'Shopee Pte. Ltd.'
        else:
            result = process.extractOne(nama_input_lower, choices, scorer=fuzz.token_sort_ratio)
            if result and result[1] >= threshold:
                return standard_dict[result[0]]
            else:
                return 'PT Shopee Internasional Indonesia'

    # Fuzzy matching standar
    nama_input_bersih = bersihkan_nama(nama_input)
    result = process.extractOne(nama_input_bersih, choices, scorer=fuzz.token_sort_ratio)
    if result and result[1] >= threshold:
        return standard_dict[result[0]]
    return None

def match_nama(nama_input, standard_dict, threshold=90):
    """Fuzzy matching tanpa lokasi"""
    if pd.isna(nama_input) or nama_input == '-':
        return None

    nama_input_bersih = bersihkan_nama(nama_input)
    choices = list(standard_dict.keys())
    result = process.extractOne(nama_input_bersih, choices, scorer=fuzz.token_sort_ratio)
    if result and result[1] >= threshold:
        return standard_dict[result[0]]
    return None

# Fungsi standardisasi dengan Gemini AI
def standardize_company_name(company_name, model):
    """Standardisasi nama perusahaan menggunakan Gemini API"""
    if pd.isna(company_name) or company_name == '' or company_name == '-':
        return company_name

    prompt = f"""
    Standardisasi nama perusahaan berikut ke format resmi/formal-nya.
    Ikuti aturan berikut:
    - Gunakan format PT untuk Perseroan Terbatas (bukan PT.)
    - Gunakan format CV (bukan CV.)
    - Tambahkan (Persero) untuk perusahaan yang termasuk BUMN dalam bentuk perseroan
    - Tambahkan Tbk untuk perusahaan terbuka (bukan Tbk.)
    - Jika tidak yakin, pertahankan nama aslinya
    - Berikan output berupa nama perusahaan saja tanpa penjelasan apapun

    Contoh:
    - "BCA" ‚Üí "PT Bank Central Asia Tbk"
    - "BCA Digital" ‚Üí "PT Bank Digital BCA"
    - "BTPN" ‚Üí "PT Bank Tabungan Pensiunan Nasional Tbk"
    - "PT Bank BPTN" ‚Üí "PT Bank Tabungan Pensiunan Nasional Tbk"
    - "Mandiri" ‚Üí "PT Bank Mandiri (Persero) Tbk"
    - "Bank BRI" ‚Üí "PT Bank Rakyat Indonesia (Persero) Tbk"
    - "BRI" ‚Üí "PT Bank Rakyat Indonesia (Persero) Tbk"
    - "BNI" ‚Üí "PT Bank Negara Indonesia (Persero) Tbk"
    - "PermataBank" ‚Üí "PT Bank Permata Tbk"
    - "Danamon" ‚Üí "PT Bank Danamon Indonesia Tbk"
    - "BI" `‚Üí "Bank Indonesia"
    - "Telkom" ‚Üí "PT Telkom Indonesia Tbk"
    - "Pertamina" ‚Üí "PT Pertamina (Persero)"
    - "Pertamina Hulu Rokan" ‚Üí "PT Pertamina Hulu Rokan"
    - "PHR" ‚Üí "PT Pertamina Hulu Rokan"
    - "Schlumberger" ‚Üí "PT Schlumberger Indonesia"
    - "Halliburton" ‚Üí "PT Halliburton Indonesia"
    - "Weatherford" ‚Üí "Weatherford Indonesia"
    - "Skintific" ‚Üí "PT May Sun Yvan"
    - "Shopee Indonesia" ‚Üí "PT Shopee Internasional Indonesia"
    - "White.id" ‚Üí "WIT.id"
    - "Ninja Xpress"  ‚Üí "NinjaXpress"
    - "PUPR" ‚Üí "Kementerian Pekerjaan Umum dan Perumahan Rakyat"
    - "Ecoedu" ‚Üí "PT Eco Edu Indonesia"
    - "CV. XOSO" ‚Üí "CV XOSO"
    - "Bonvie" ‚Üí "Bonvie (PT Kreasi Semangat Muda)"
    - "BTPN" ‚Üí "PT Bank Tabungan Pensiunan Nasional Tbk"
    - "Mandiri" ‚Üí "PT Bank Mandiri (Persero) Tbk"
    - "BRI" ‚Üí "PT Bank Rakyat Indonesia (Persero) Tbk"
    - "BNI" ‚Üí "PT Bank Negara Indonesia (Persero) Tbk"
    - "PermataBank" ‚Üí "PT Bank Permata Tbk"
    - "Danamon" ‚Üí "PT Bank Danamon Indonesia Tbk"
    - "Telkom" ‚Üí "PT Telkom Indonesia Tbk"
    - "Pertamina Hulu Rokan" ‚Üí "PT Pertamina Hulu Rokan"
    - "PHR" ‚Üí "PT Pertamina Hulu Rokan"
    - "Schlumberger" ‚Üí "PT Schlumberger Indonesia"
    - "Halliburton" ‚Üí "PT Halliburton Indonesia"
    - "Weatherford" ‚Üí "Weatherford Indonesia"
    - "Skintific" ‚Üí "PT May Sun Yvan"
    - "Shopee" ‚Üí "PT Shopee Internasional Indonesia"
    - "White.id" ‚Üí "WIT.id"
    - "Ninja Xpress"  ‚Üí "NinjaXpress"
    - "PUPR" ‚Üí "Pekerjaan Umum dan Perumahan Rakyat"
    - "Accenture" ‚Üí "PT Accenture Indonesia"
    - "ABeam Consulting" ‚Üí "PT ABeam Consulting Indonesia"
    - "Adira Finance" ‚Üí "PT Adira Dinamika Multi Finance Tbk."
    - "Agate" ‚Üí "PT Agate International"
    - "Akulaku" ‚Üí "PT Akulaku Silvrr Indonesia"
    - "Allianz" ‚Üí "PT Asuransi Allianz Life Indonesia"
    - "Alodokter" ‚Üí "PT Alodokter Teknologi Solusi"
    - "Ameliore" ‚Üí "PT Ameliore Solusi Analitika"
    - "Annisa Surya Kencana" ‚Üí "PT Annisa Surya Kencana"
    - "AMF" ‚Üí "Anwar Muhammad Foundation"
    - "Anugerah Samudera Madanindo" ‚Üí "PT Anugerah Samudera Madanindo"
    - "Arayya Tama Mandiri" ‚Üí "PT Arayya Tama Mandiri"
    - "Arwana Citramulia" ‚Üí "PT Arwana Citramulia Tbk."
    - "Asahimas Chemical" ‚Üí "PT Asahimas Chemical"
    - "Aurecon Indonesia" ‚Üí "PT Aurecon Indonesia"
    - "PwC" ‚Üí "PricewaterhouseCoopers"
    - "Ruangguru" ‚Üí "Ruangguru (PT Ruang Raya Indonesia)"
    - "CAD IT" ‚Üí "CAD-IT Consultants Asia Pte Ltd (Indonesia Representative Office)"
    - "Bukalapak" ‚Üí "PT Bukalapak.com Tbk"
    - "Bonvie" ‚Üí "PT Kreasi Semangat Muda"
    - "Ecomindo" ‚Üí "PT Ecomindo Saranacipta"
    - "National Urban Water Supply Project (NUWSP) Kementerian PUPR" ‚Üí "National Urban Water Supply Project Kementerian Pekerjaan Umum dan Perumahan Rakyat"
    - "Bumi Resources Minerals" ‚Üí "PT Bumi Resources Minerals Tbk"
    - "Toyota Astra Motor" ‚Üí "PT Toyota-Astra Motor"
    - "Pinhome" ‚Üí "PT Properti Solusi Manajemen"
    - "PT Tungal Inti Kahuripan" ‚Üí "PT Tunggal Inti Kahuripan"
    - "Oy!" ‚Üí "PT Dompet Harapan Bangsa"
    - "Schlumbergerz" ‚Üí "PT Schlumberger Geophysics Nusantara"
    - "Blibli" ‚Üí "Blibli (PT Global Digital Niaga)"
    - "APRIL Group" ‚Üí APRIL GROUP (PT Riau Andalan Pulp & Paper)
    - "PT Riau Andalan Pulp & Paper" ‚Üí APRIL GROUP (PT Riau Andalan Pulp & Paper)
    - "OVO" ‚Üí "OVO (PT Visionet Internasional)"
    - Agree (PT Telekomunikasi Indonesia Tbk)
    - Astra Financial (PT Sedaya Multi Investama)
    - Badan Informasi Geospasial (BIG)
    - Badan Pengusahaan Batam (BP Batam)
    - Bank of China (Hong Kong Limited Jakarta Branch)
    - Beehive Drones (PT Aerotek Global Inovasi)
    - Zuellig Pharma (PT Anugerah Pharmindo Lestari)
    - Zenmed (PT Zenith Allmart Precisindo)
    - Xendit (PT Sinar Digital Terdepan)
    - Worldwhite Enterprise (WE Group)
    - Wings Group (PT Sayap Mas Utama)
    - Waresix (PT Tibeka Logistik Indonesia)
    - Verdant Bioscience (PT Timbang Deli Indonesia)
    - Uniqlo (PT Fast Retailing Indonesia)
    - Trees4trees (Yayasan Bumi Hijau)
    - Trans 7 (PT Duta Visual Nusantara Tivi Tujuh)
    - Tim Akeselerasi Pembangunan (TAP) Jawa Barat
    - Su-re.co (Sustainability & Resilience)
    - Schoters (PT Partner Impian Milenial)
    - Securxcess (PT Sekur Inti Permata)
    - Sayurbox (PT Kreasi Nostra Mandiri)
    - PwC Indonesia (PT PricewaterhouseCoopers Indonesia Advisory)
    - PT Wooden Fish Village (Nuanu Architect)
    - PT Kalbe Farma Tbk. (Stem Cell & Cancer Institute)

    Nama perusahaan: {company_name}

    Nama resmi:
    """

    max_retries = 5  # Maksimal percobaan ulang
    base_delay = 1   # Jeda awal dalam detik

    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            standardized_name = response.text.strip()

            if len(standardized_name) > 100 or len(standardized_name.split('\n')) > 1:
                return company_name

            return standardized_name
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = base_delay * (2 ** attempt) + random.random() * 0.1
                time.sleep(wait_time)
            else:
                return company_name

    return company_name

def process_companies_with_ai(company_names, model, requests_per_minute=10):
    """Proses batch nama perusahaan dengan Gemini AI"""
    standardized_names = {}
    delay_per_request = (60 / requests_per_minute) + 0.5

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, name in enumerate(company_names):
        status_text.text(f"Processing: {name}")
        standardized = standardize_company_name(name, model)
        standardized_names[name] = standardized

        progress_bar.progress((i + 1) / len(company_names))

        if i < len(company_names) - 1:
            time.sleep(delay_per_request)

    status_text.text("Processing complete!")
    return standardized_names

# Fungsi utama pemrosesan
def process_file(df, reference_dfs, model, requests_per_minute=10, address_column=None):
    """Proses file utama dengan fuzzy matching dan AI"""

    # Buat dictionary referensi
    standard_dict = create_reference_dict(reference_dfs)

    # Step 1: Fuzzy matching pertama
    st.write("### Step 1: Fuzzy Matching")
    if address_column and address_column in df.columns:
        st.info(f"Menggunakan kolom alamat: {address_column}")
        df['company_name_standardized_fuzzy1'] = df.apply(
            lambda row: match_nama_with_location(
                row['company_name'],
                row[address_column],
                standard_dict
            ), axis=1
        )
    else:
        st.info("Menggunakan fuzzy matching tanpa lokasi")
        df['company_name_standardized_fuzzy1'] = df['company_name'].apply(
            lambda x: match_nama(x, standard_dict)
        )

    matched_count_1 = df['company_name_standardized_fuzzy1'].notnull().sum()
    st.success(f"Fuzzy matching 1: {matched_count_1}/{len(df)} ({matched_count_1/len(df)*100:.1f}%)")

    # Step 2: AI Standardization untuk yang tidak cocok
    st.write("### Step 2: AI Standardization")
    unmatched_mask = df[df['company_name_standardized_fuzzy1'].isna()].index
    unmatched_companies = df.loc[unmatched_mask, 'company_name'].tolist()

    if unmatched_companies and model:
        st.info(f"Processing {len(unmatched_companies)} companies with Gemini AI...")
        standardized_dict = process_companies_with_ai(unmatched_companies, model, requests_per_minute)

        # Update dataframe
        df['company_name_standardized_ai'] = df['company_name'].map(standardized_dict)

        ai_count = df['company_name_standardized_ai'].notnull().sum()
        st.success(f"AI standardization: {ai_count} companies processed")
    else:
        df['company_name_standardized_ai'] = None
        st.warning("No AI processing (no API key or no unmatched companies)")

    # Step 3: Fuzzy matching kedua untuk hasil AI
    st.write("### Step 3: Second Fuzzy Matching")

    # Update dictionary dengan hasil AI
    # ai_results = df['company_name_standardized_ai'].dropna().unique()
    # for ai_result in ai_results:
    #     nama_bersih = bersihkan_nama(ai_result)
    #     if nama_bersih:
    #         standard_dict[nama_bersih] = ai_result

    # Fuzzy matching untuk hasil AI
    df['company_name_standardized_fuzzy2'] = df['company_name_standardized_ai'].apply(
        lambda x: match_nama(x, standard_dict) if pd.notna(x) else None
    )

    # Gabungkan hasil
    df['company_name_standardized_final'] = df['company_name_standardized_fuzzy1'].fillna(
        df['company_name_standardized_fuzzy2'].fillna(df['company_name_standardized_ai'])
    )

    final_count = df['company_name_standardized_final'].notnull().sum()
    st.success(f"Final result: {final_count}/{len(df)} ({final_count/len(df)*100:.1f}%)")

    return df

# UI Streamlit
def main():
    st.title("üè¢ Company Name Standardization Tool")
    st.markdown("Upload Excel files to standardize company names using fuzzy matching and AI")

    # Sidebar untuk konfigurasi
    st.sidebar.header("Configuration")

    # API Key input
    api_key = st.sidebar.text_input("Gemini API Key", type="password", help="Enter your Google Gemini API key")
    model = None
    if api_key:
        model = setup_gemini_api(api_key)
        if model:
            st.sidebar.success("API connected")
        else:
            st.sidebar.error("API connection failed")

    # Rate limiting
    requests_per_minute = st.sidebar.slider("Requests per minute", 1, 60, 10)

    # File upload
    st.header("üìÅ File Upload")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Main Data File")
        main_file = st.file_uploader(
            "Upload main Excel file to process",
            type=['xlsx', 'xls'],
            help="File containing company names to standardize"
        )

    with col2:
        st.subheader("Reference Files")
        reference_files = st.file_uploader(
            "Upload reference Excel files",
            type=['xlsx', 'xls'],
            accept_multiple_files=True,
            help="Files containing standardized company names for reference"
        )

    if main_file:
        # Load main file
        try:
            df_main = pd.read_excel(main_file)
            st.success(f"Main file loaded: {len(df_main)} rows")

            # Show preview
            with st.expander("Preview Main Data"):
                st.dataframe(df_main.head())

            # Column selection
            st.subheader("Column Configuration")

            # Company name column
            company_col = st.selectbox(
                "Select company name column",
                df_main.columns.tolist(),
                index=0 if 'company_name' in df_main.columns else 0
            )

            # Address column (optional)
            address_cols = ['None'] + df_main.columns.tolist()
            address_col = st.selectbox(
                "Select address column (optional)",
                address_cols,
                index=address_cols.index('bekerja_alamat_kantor') if 'bekerja_alamat_kantor' in address_cols else 0
            )
            address_col = None if address_col == 'None' else address_col

            # Load reference files
            reference_dfs = []
            if reference_files:
                for ref_file in reference_files:
                    try:
                        ref_df = pd.read_excel(ref_file)
                        reference_dfs.append(ref_df)
                        st.success(f"Reference file loaded: {ref_file.name} ({len(ref_df)} rows)")
                    except Exception as e:
                        st.error(f"Error loading {ref_file.name}: {str(e)}")

            # Process button
            if st.button("Start Processing", type="primary"):
                if not reference_dfs:
                    st.warning("No reference files loaded. Processing with empty reference.")

                # Rename company column for consistency
                df_main = df_main.rename(columns={company_col: 'company_name'})

                with st.spinner("Processing..."):
                    processed_df = process_file(
                        df_main,
                        reference_dfs,
                        model,
                        requests_per_minute,
                        address_col
                    )

                st.success("üéâ Processing complete!")

                # Show results
                st.subheader("Results")

                # Statistics
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric("Total Records", len(processed_df))

                with col2:
                    fuzzy1_count = processed_df['company_name_standardized_fuzzy1'].notnull().sum()
                    st.metric("Fuzzy Match 1", fuzzy1_count)

                with col3:
                    ai_count = processed_df['company_name_standardized_ai'].notnull().sum()
                    st.metric("AI Standardized", ai_count)

                with col4:
                    final_count = processed_df['company_name_standardized_final'].notnull().sum()
                    st.metric("Final Standardized", final_count)

                # Show sample results
                with st.expander("Sample Results"):
                    sample_cols = ['company_name', 'company_name_standardized_final']
                    if 'company_name_standardized_fuzzy1' in processed_df.columns:
                        sample_cols.insert(1, 'company_name_standardized_fuzzy1')
                    if 'company_name_standardized_ai' in processed_df.columns:
                        sample_cols.insert(-1, 'company_name_standardized_ai')

                    st.dataframe(processed_df[sample_cols].head(20))

                # Download section
                st.subheader("Download Results")

                # Prepare download
                output = BytesIO()
                processed_df.to_excel(output, index=False)
                output.seek(0)

                st.download_button(
                    label="Download Excel File",
                    data=output.getvalue(),
                    file_name=f"standardized_{main_file.name}",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

                # Show unmatched companies
                unmatched_mask = processed_df['company_name_standardized_final'].isna()
                unmatched_count = unmatched_mask.sum()

                if unmatched_count > 0:
                    with st.expander(f"Unmatched Companies ({unmatched_count})"):
                        unmatched_companies = processed_df.loc[unmatched_mask, 'company_name'].dropna().unique()
                        for company in unmatched_companies[:20]:  # Show first 20
                            st.write(f"- {company}")
                        if len(unmatched_companies) > 20:
                            st.write(f"... and {len(unmatched_companies) - 20} more")

        except Exception as e:
            st.error(f"Error loading main file: {str(e)}")

    # Help section
    with st.expander("‚ÑπÔ∏è Help"):
        st.markdown("""
        ### How to use this tool:

        1. **Upload Main File**: Excel file containing company names to standardize
        2. **Upload Reference Files**: Excel files with standardized company names (optional)
        3. **Configure Columns**: Select which columns contain company names and addresses
        4. **Set API Key**: Enter your Google Gemini API key for AI standardization
        5. **Process**: Click "Start Processing" to begin

        ### Process Steps:
        1. **Fuzzy Matching**: Matches company names against reference data
        2. **AI Standardization**: Uses Gemini AI to standardize unmatched names
        3. **Second Fuzzy Matching**: Matches AI results to validate AI Standardization's answers

        ### File Requirements:
        - Main file should have a column with company names
        - Reference files should have 'company_name_standardized' column
        - Address column is optional but helps with location-specific matching
        """)

if __name__ == "__main__":
    main()